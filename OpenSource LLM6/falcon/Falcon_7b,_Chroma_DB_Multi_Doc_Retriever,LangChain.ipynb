{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arj7Z-22Dcd5",
        "outputId": "91accd25-367c-4944-e9dc-7af1e415298b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Collecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=a221b540fa616c76ec5dc24d99f888dc268bf3777ea3e75eb9c22e766d224d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, safetensors, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.14.1 transformers-4.35.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.8/496.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m912.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers\n",
        "!pip -q install langchain tiktoken chromadb pypdf transformers\n",
        "!pip -q install accelerate bitsandbytes sentencepiece Xformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "TgrCA_1fDsSv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Shafi2016/Youtube/raw/main/stock_market_june_2023.zip -O stock_market_june_2023.zip\n",
        "!unzip stock_market_june_2023.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCrKu900DsQe",
        "outputId": "56a309d2-3a4b-445f-c1c1-2ba2f2ce47ca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-11 08:07:51--  https://github.com/Shafi2016/Youtube/raw/main/stock_market_june_2023.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Shafi2016/Youtube/main/stock_market_june_2023.zip [following]\n",
            "--2023-11-11 08:07:51--  https://raw.githubusercontent.com/Shafi2016/Youtube/main/stock_market_june_2023.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10638 (10K) [application/zip]\n",
            "Saving to: ‘stock_market_june_2023.zip’\n",
            "\n",
            "stock_market_june_2 100%[===================>]  10.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-11 08:07:51 (92.4 MB/s) - ‘stock_market_june_2023.zip’ saved [10638/10638]\n",
            "\n",
            "Archive:  stock_market_june_2023.zip\n",
            "   creating: stock_market_june_2023/\n",
            "  inflating: stock_market_june_2023/Arbor Metals Corp.txt  \n",
            "  inflating: stock_market_june_2023/Intuitive Surgical.txt  \n",
            "  inflating: stock_market_june_2023/Kiplin Metals Inc.txt  \n",
            "  inflating: stock_market_june_2023/Mercado Libre.txt  \n",
            "  inflating: stock_market_june_2023/Microsoft Corporation.txt  \n",
            "  inflating: stock_market_june_2023/NVIDIA Corporation.txt  \n",
            "  inflating: stock_market_june_2023/Shopify.txt  \n",
            "  inflating: stock_market_june_2023/stock_market.txt  \n",
            "  inflating: stock_market_june_2023/Tesla Inc.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initializes a DirectoryLoader to load text files from the specified directory.\n",
        "loader = DirectoryLoader('./stock_market_june_2023/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "# Loads all the documents present in the directory.\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "uzBv_1s_DsN-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "WgEgU4hZFSHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff884e0a-3e3e-413a-edb6-b9a3086fd4a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='The global shift towards electric vehicles (EVs) is driving an exponential increase in electricity demand. Countries worldwide, including oil-producing nations, are turning to nuclear energy to meet this growing need while transitioning away from fossil fuels. Consequently, the demand for uranium, essential for fueling the nuclear power sector, has experienced a significant surge in the past year after decades of stagnation, clearly showcased in the uranium spot price.\\n\\nEveryone is drilling for uranium, and companies like Kiplin Metals Inc. (TSXV: KIP | FWB: 17G1 | OTC: ALDVF), which are strategically located in uranium-rich regions like Saskatchewan, Canada, stand to gain the most.\\nKiplin’s mining location next to Cluff Lake in Saskatchewan is a known vein of uranium that attracted companies like Urano in the past. The area has historically produced approximately 62,000,000 lbs of yellowcake uranium, making it a competitive place for other companies to buy claims. \\n\\nEvery mining company in Kiplin’s immediate area is continuing to discover rich uranium core samples, and experts predict that Kiplin Metals is poised to follow the success of previous neighbouring ventures as its summer exploration program gets underway. \\n\\nAs the demand for uranium remains strong, Kiplin is well-positioned to capitalize on the growing market, and its stock is primed for substantial returns.', metadata={'source': 'stock_market_june_2023/Kiplin Metals Inc.txt'}),\n",
              " Document(page_content='Speaking of AI, NVIDIA (NASDAQ: NVDA) is already leading the charge to capitalize on this new megatrend. \\nWith the unveiling of OpenAI’s ChatGPT in late 2022, generative AI has moved from a tech buzzword to a powerful megatrend with the potential to revolutionize various industries by enhancing human productivity and creativity.\\nMarket analysts anticipate the AI sector to grow twentyfold, reaching nearly $2 trillion by the close of 2030 as the technology pervades domains from supply chains to mobile applications. If you equate this opportunity to the oil boom, Nvidia isn’t drilling for oil, but providing the drills and equipment necessary—a more secure and lucrative approach.\\n\\nNvidia dominates with an impressive 80% market share in advanced graphics processing units (GPUs), integral to training AI platforms like ChatGPT, which utilizes 10,000 of its A100 chips. As generative AI platforms advance and update, they will likely demand a larger volume of comparable hardware.\\n\\nWith each of Nvidia’s A100s retailing for approximately $10,000, an increase in AI-related demand could significantly bolster the company’s revenue as it amalgamates AI into its traditional business. However, Alphabet claims that a supercomputer powered by the company’s latest fourth-generation TPU outpaced Nvidia’s A100 by 1.7 times in speed while consuming less power.\\n\\nThis a moot point, as Alphabet could be more of an opportunity than a threat for Nvidia. In May, the search giant announced its A3 supercomputers engineered to assist clients in training the most demanding generative AI models. The catch? A3 relies on Nvidia’s H100 chips, reinforcing confidence in the GPU maker’s technological leadership. \\n\\nNvidia’s shares have seen a massive surge since the beginning of 2023, indicating that the market recognizes the company’s substantial potential in the AI industry. While some may consider the stock to be pricy, Nvidia has a lot of things going for it to help justify the premium price tag. \\n', metadata={'source': 'stock_market_june_2023/NVIDIA Corporation.txt'}),\n",
              " Document(page_content='Future-proofing your portfolio with growth stocks isn’t just about singling out products and industries that will always be in demand. \\nIt’s also about identifying companies engineered from inception to adapt to industry shifts. Microsoft (NASDAQ: MSFT) fits these criteria like a glove.\\nThe internet was still budding three decades ago, while cloud computing wasn’t even a concept. As technology evolved, so did Microsoft. The company now excels in various fields, including cloud computing, online ad management, business collaboration, video gaming, and innovations and investments related to AI. While still vital, its Windows operating system segment has taken a backseat in light of the company’s recent successes.\\n\\nLet’s focus on Microsoft’s artificial intelligence (AI) prospects. As AI propels itself into the mainstream, it’s not surprising to see investors eager to fortify their portfolios with AI stocks. Microsoft’s recent $1 billion investment in OpenAI – the creator of ChatGPT and the AI image generator Dall-E- positions the stock as a prime candidate for investment.\\n\\nThis Microsoft-OpenAI partnership clearly conveys Microsoft’s intent and efforts to incorporate AI capabilities into its services. Starting with its cloud service, Azure – second only to Amazon Web Services (AWS) in global cloud market share and a key component of Microsoft’s business – Microsoft is showcasing its commitment to AI.\\n\\nMicrosoft’s strategic move to integrate OpenAI’s products within its platform positions the company as a preferred platform for organizations looking to develop AI models or incorporate them into their business operations. Microsoft’s focus on building AI tools as platforms is a savvy strategic decision that will likely broaden its already considerable enterprise customer base and service suite.\\n', metadata={'source': 'stock_market_june_2023/Microsoft Corporation.txt'}),\n",
              " Document(page_content='Shopify (NYSE: SHOP) has 55% increase in its shares so far in 2023. Despite ongoing price fluctuations, Shopify’s business and growth trajectory are moving upward.\\nIn the seven years since its initial public offering, Shopify has been profitable in five, a commendable track record in an industry known for widespread unprofitability. The company has weathered economic volatility, including the challenges posed by the pandemic, by streamlining its focus on delivering market-leading software and solutions to empower its merchant clients.\\n\\nTo adapt to the changing landscape, Shopify implemented significant changes, including workforce layoffs of approximately 20% and selling its logistics business to Flexport. Although these changes incur near-term expenses, such as restructuring and impairment charges, they will ultimately reduce overhead costs and make Shopify more asset-light in the long run.\\n\\nIn Q1, Shopify returned to profitability and achieved positive free cash flow. Management expects the company to remain cash-flow-positive for the full year, highlighting its financial resilience.\\n\\nDespite not being commonly associated with AI, Shopify has recently introduced several AI products. For example, its machine-learning platform, Merlin, supports various use cases, from fraud detection and revenue predictions to product categorization and buyer recommendations. Shopify also integrated an intelligent chatbot called Shop.ai into its mobile app, serving as a consumer shopping assistant.\\n\\nFurthermore, Shopify Audiences, a marketing software utilizing machine learning, allows creating and exporting customer lists to platforms like Pinterest, Facebook, Instagram, and Google for targeted ad campaigns. The adoption of Shopify Audiences by merchants upgrading to Shopify Plus presents a promising growth opportunity.\\n\\nShopify’s ongoing commitment to innovation and expansion into AI and upmarket segments positions it for continued success and growth.\\n', metadata={'source': 'stock_market_june_2023/Shopify.txt'}),\n",
              " Document(page_content='In the context of an imminent lithium market boom, why not invest in the world’s leading EV producer instead of just its lithium suppliers? \\nDoubling down on investments in both lithium producers and consumers is a smart investment strategy, especially as lithium stocks are primed for \\nsignificant growth in the forthcoming years—a winning recipe to future-proof your portfolio.\\nIn March, Elon Musk unveiled Tesla’s (NASDAQ: TSLA) Master Plan Part 3, envisioning a long-term goal of nurturing a sustainable future without inflicting environmental harm. The plan anticipates a staggering $10 trillion investment, which Musk deems feasible and “not a big number relative to the global economy.”\\n\\nTesla is already diving into the lithium sector with substantial investments. In a previous earnings call, Musk revealed the company’s intent to set up a lithium refinery in Corpus Christi, Texas, to fortify control over its battery production supply chain. This proposed $375 million facility aims to convert raw materials into battery-grade lithium hydroxide, an essential component for Tesla’s EV batteries.\\n\\nDuring the Q&A segment of the 2023 Annual Shareholders’ Meeting, Musk shed light on Tesla’s peak margin upon achieving full autonomy. When asked to estimate Tesla’s anticipated peak margin in its automotive and energy businesses, Musk predicted an impressive 80% for Tesla’s automotive segment and a robust 20-30% for Tesla Energy.\\n\\nMusk’s vision is coming true by the day, with the company’s Model Y becoming the world’s best-selling vehicle in Q1 2023.\\n\\nYou probably already own Tesla stock by now, but why stop there? Take a step further and amplify your returns by investing more in Tesla and tapping into the affordable Arbor Metals as a lithium supplier to drive unmatched profit growth and future-proofing in the upcoming decades as the lithium and EV industries continue to grow exponentially.', metadata={'source': 'stock_market_june_2023/Tesla Inc.txt'}),\n",
              " Document(page_content='Intuitive Surgical (NASDAQ: ISRG) has dominated the surgical robotics industry for over two decades, maintaining a massive 80% market share. \\nIntuitive Surgical remains unrivalled despite other healthcare companies’ introduction of competing products.\\nThe global surgical robotics market is projected to reach nearly $100 billion by the next decade, driven by the increasing demand for these systems in minimally invasive and open surgeries. Intuitive Surgical is well-positioned to capitalize on this growth.\\n\\nThe industry faced significant challenges in recent years. The COVID-19 pandemic led to the cancellation and postponement of many surgical procedures. Resurgences in cases, particularly in Asia, continue to impact procedure volumes. Inflation and a shortage of healthcare workers have also raised operational costs for hospitals, affecting the adoption of surgical systems.\\n\\nDespite these obstacles, Intuitive Surgical has expanded revenue, maintained profitability, and increased system installations and customer training. The company generates revenue from surgical systems and recurring sources such as software, training, and customer support.\\n\\nIn Q1 2023, recurring revenue accounted for 81% of Intuitive Surgical’s $1.7 billion total revenue, showing a 21% increase compared to the previous year. Total revenue grew by 17% year over year on a currency-neutral basis, with a net income of $355 million.\\n\\nIntuitive Surgical has seen a 12% increase in its da Vinci Systems installed worldwide compared to the prior-year quarter. Despite the ongoing recovery of procedure volumes, the company’s resilient revenue model and steady growth demonstrate the strength of its business.', metadata={'source': 'stock_market_june_2023/Intuitive Surgical.txt'}),\n",
              " Document(page_content='The stock market had a strong month in May, especially for those who read our previous monthly stock recommendation. At The Markets Watch, our journalists and analysts have compiled a list of monthly stock opportunities for buy-and-hold investors and traders looking to buy great companies at an even better price.\\nLooking at some of our stock suggestions from the previous month, the evidence of our team’s expertise becomes compelling. In May:\\n\\nPalantir soared by over 74%\\nNvidia witnessed a growth of over 34%\\nCrowdstrike Holdings increased by over 30%\\nShopify saw a rise of over 19%\\nOur insights and articles about these stocks collectively yielded a remarkable 57% return last month for our readers who took action on our recommendations.\\n\\nInstitutional ETFs assembled by Goldman Sachs and Vanguard rely on growth stocks to drive their price in all market conditions, and your portfolio is no different. Most of our recommendations are already a staple in these ETFs, but for investors looking to cherry-pick the best stocks, we have assembled this list for you.\\n\\nHere are 8 growth stocks for you to buy in June 2023 set to leverage emerging industry trends, such as AI, the lithium “gold” rush, blockbuster EV sales, and ESG.\\n\\nArbor Metals Corp.\\nTesla Inc.\\nKiplin Metals Inc.\\nMicrosoft\\nNVIDIA\\nShopify\\nIntuitive Surgical\\nMercadoLibre\\nGrowth stocks like these are ideal for investors seeking short-term gains and long-term resilience. These companies are primed to withstand future market fluctuations through innovation, market opportunities, embedding in recession-resistant sectors, and committing to diversifying their portfolios.\\n\\nFor our top pick, our analysts have issued a rare ‘Buy Now‘ alert as Arbor Metals Corp. (TSX-V: ABR, FWB: 432, OTC: ABRMF) is forecasted to soar exponentially in 2023. The Canadian mineral exploration company is on the verge of making a significant lithium discovery in one of its properties, just as the lithium industry braces itself for a bullish surge.', metadata={'source': 'stock_market_june_2023/stock_market.txt'}),\n",
              " Document(page_content='Arbor Metals Corp.\\nArbor Metals (TSX-V: ABR, FWB: 432, OTC: ABRMF) is a mineral exploration company that finds itself in the media spotlight as \\nCanada continues to attract massive investments across the lithium and electric vehicle (EV) sectors. \\nMajor media channels like Yahoo Finance, Financial Times, and CNN Business have recently focused on Arbor Metals Corp.’s strategic \\nlocation in the James Bay region of Quebec.\\nWith an impressive 126% annualized return over the past four years, Arbor’s shareholders have every reason to buy more and continue to hold onto their shares, especially given the company’s recent activities and the upcoming opportunities in the burgeoning Canadian lithium industry.\\n\\nThe company’s stock has had a historical trading volume increase over the last two months as expectations of its exploration program continue to be positive.\\n\\nAmbitious projects like Volkswagen’s 20 billion lithium-ion battery factory in Ontario signal massive growth for all local lithium mining stocks as the car makers actively seek lithium suppliers. Strategically located in a lithium-rich region of James Bay in northern Quebec, Arbor Metals’ Jarnet Lithium Project is positioned close to the planned factory.\\n\\nThe James Bay region boasts numerous lithium discoveries. One prime example is the lithium trend discovered on an adjacent property owned by Patriot Battery Metals (TSX-V: PMET). This lithium trend has been documented to extend toward Arbor’s Jarnet project, meaning Arbor will be the next to benefit from this discovery.\\n\\nThese developments prompted Arbor to enlist satellite imagery and infrared surveys to map and uncover new lithium deposits on their property. With a promising exploration program for 2023 underway, there are high hopes to unlock the new lithium resources, sharing this lithium growth trend with Patriot and other neighbouring sites.\\n\\nPatriot’s stock experienced a substantial surge of over 480% over the past year following the confirmation of its lithium discovery. Since industry geologists are even more optimistic about a larger find on Arbor’s property, analysts forecast a steep climb for Arbor’s stock in 2023, contingent on positive results from the company’s exploration program.\\n\\nArbor has the greatest upshot potential of all lithium companies right now and is great for short-term gains and long-term investors who would like to dependably profit from the growing EV market.', metadata={'source': 'stock_market_june_2023/Arbor Metals Corp.txt'}),\n",
              " Document(page_content='MercadoLibre (NASDAQ: MELI), the Latin American e-commerce and fintech giant, has achieved its third consecutive all-time high for \\nquarterly net income in Q1 2023. Its stock price has surged by 57% this year, reflecting the company’s remarkable 58% sales \\ngrowth (adjusted for foreign exchange) and its decade-long success.\\nMercadoLibre holds a logistical dominance in Latin America similar to Amazon’s in the United States. Its shipping segment, Mercado Envíos, shipped over 302 million items, with 77% of products delivered within 48 hours. \\n\\nThis rapid delivery, coupled with a 93% penetration rate among sellers utilizing Envíos’ fulfillment and cross-docking solutions, underscores the compelling value proposition of partnering with MercadoLibre and its extensive logistical network.\\n\\nMercadoLibre’s valuation is estimated to be between its 18 times free cash flow (FCF) and its price-to-earnings (P/E) ratio of 107. With the rollout of a new advertising console in Q1, the company’s profitability is expected to improve further. Advertising sales, which currently account for only 1.4% of MercadoLibre’s gross merchandise volume (GMV), are projected to outpace GMV growth, contributing to sustained profitability and long-term stock returns.\\n', metadata={'source': 'stock_market_june_2023/Mercado Libre.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes a RecursiveCharacterTextSplitter with a specified chunk size and overlap.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# Splits the loaded documents into chunks of text using the defined text_splitter.\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "X5PBJR-OFTQw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8vQrYexFfNf",
        "outputId": "83bd13e2-8e29-474c-d1f2-a0aaa873ef6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cj3wxhxFikp",
        "outputId": "3b034b32-5e1d-4a10-f246-001e6f41c220"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Kiplin’s mining location next to Cluff Lake in Saskatchewan is a known vein of uranium that attracted companies like Urano in the past. The area has historically produced approximately 62,000,000 lbs of yellowcake uranium, making it a competitive place for other companies to buy claims.', metadata={'source': 'stock_market_june_2023/Kiplin Metals Inc.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## falcon-7b-instruct"
      ],
      "metadata": {
        "id": "YcJGVP08FuJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "model = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577,
          "referenced_widgets": [
            "23ace39444cd4ac089e59eaeb0fc4c27",
            "cd637903c7ea46bbb80877bd2000b402",
            "881b48a1ea0a4b838cf078f2ce8e8644",
            "3b3a6ed0054a4f2e93a15e952225d7b1",
            "b5ca17c46ad64a27b48579ae5a45d5d0",
            "cbb734785c504deebc8d7272b9b15900",
            "f4a2216a2fbc44978797c3d86352838c",
            "2a76eb4131e34d85b6d3e18301267810",
            "de10d852c70e4c5c8685f93e8d0be051",
            "8210dcfd1d2a4218b2f11e2e4595d8cf",
            "ac7896e5846148c782dbdcb0166603e4",
            "acec74060c824291a06a11509e6abc97",
            "1187b61b02694f1d9a01e50a75926cdd",
            "5abe4567cf9249d4bd1f6af7c5e2a1a8",
            "e797a908767c42cca5e1a406ceec0c76",
            "8901dba08b6f47be9489d3f5755f3294",
            "db9dc0b1377548ec8497dec899300938",
            "70147cf9ce154fd2b85b7599ddc4de6e",
            "05d88e6fb0834958a7e977bdfd638601",
            "2ad4edf4da7f4c74a88e0401993aaa01",
            "be7fd9de05634d9a847b06bb8b7406ec",
            "2b1f0e6ac3cc492381423e3aec528903",
            "8c943c09cc8a4362b79e84d93c851f2f",
            "fad0ce6367a24f5282cf60d08e86127f",
            "41cd8f84e43046a382750bdc9eece57b",
            "16ce60616ff74446ad36bbd167b16d3f",
            "fabd99f539b5441a9c524e16b724a69b",
            "7183f4da5ef84b27b7bf095ffa2984f9",
            "fc4f1060b9e64807b31e2b1be0cb738e",
            "c22968d844744ba5b3a92f27357471e3",
            "dd03c81f920548a3b16ef05fcfce4701",
            "e3b23908e4714087bf53fc8946fd24f9",
            "77fcd76d85d940cc8679b01f0e5571e8",
            "fb19300ff5944d3a957758c3f348316f",
            "505e9931289248d7be4b3e77573bd2bb",
            "3988f7377b4640a08e817a5ddfd7828d",
            "33e7db630a5d49d4b5700fb355b2f1c3",
            "755f3db07b9142da91d153047da4f6b4",
            "4b333bdd405e4897ad1149765f83e1ce",
            "4dc31cf396cc4a73aa8e149f3291665c",
            "0e491aea48aa4e109164923c83ce6c7b",
            "6d3199b45a35402c9ff2e441539faf6c",
            "c4587c8809d841aa99c15d0aabc962ef",
            "acee2763783a4a7dbc70b6afc3d0fcb8",
            "5e6e7c706f904e34823c88781cb60631",
            "c5ca41cfd55e42c591dd6119ef92c98a",
            "0324787603fa4a0fb50b601a04c7b928",
            "c941d09e17394de9a12615fdb3c748a8",
            "69dc615c2f934222963fd59a3e61816f",
            "69c24ea5cc474933af32ba34316b2c84",
            "8b18f77b7ea442fab167171eb98fea35",
            "ca71f6315ca94b0dbd57cd0562fafba6",
            "8dd631514c244fc689c4cfe70a09891b",
            "d0a0254fa9d24da3b5e2ff012d50f369",
            "ef0b858fcc594539b14aaf9cfaace037",
            "1ed14ca5fea34c83a96b9c6f8264206b",
            "916dbdfdec5e4f1b9bf366d6f48da86b",
            "0c0798f237d04d23b5684a66b42e3973",
            "a71ed51e68544ed09826c6ad8611465b",
            "7e4fa5ac62d548a19b98faaa2596805a",
            "8fe28157d7634c469a23ede52812ebe3",
            "3d92ec5a774e4ff18f52ccf61741b612",
            "4a14c995593d440198ec1605376c7ef7",
            "02d3c45d2951433c888006234023cb82",
            "42c9f3625bbc494baf96836a6fadbd01",
            "3e28791719c8434f90ab133bc4ad5688",
            "11bd3678688b4890afa80a6510c27163",
            "b28eb809989b4363946ebf4d9d5b348a",
            "5a461bc0a1e146df8100e190f4199b3d",
            "aa161a6a37644320855a38533331baab",
            "93ebd1ecd01d418e85fb8d1c12daca1d",
            "47398145268a46b194bd73ab3e59beeb",
            "6eabc5137bce48cc8bf551bc59cafd92",
            "596b3ba059ff4e15b76891f3dfb96ff2",
            "bbca945226f44f77904dd2cebab9dff9",
            "6466c449a9274656b038cd282ec0c192",
            "d0630dc9f12641dcb651345290c41902",
            "fadc02fbc66e468bbe7b7dea06e485ff",
            "219ef36ae35d45d985851d8309cfa21c",
            "3c0ab68ccd5b46359ca70f94ef0255ec",
            "e0e6b22af855443b85233c56b354a6f2",
            "0c68b5d56cb944a692bc23b16dc0f9b7",
            "31da7429ae8f493dbf06281372a8e32b",
            "df8949b9dcc441bbbc142670a6bc2998",
            "8a71bb2a07fd40e59a763e6f5f18e849",
            "f8457b1f7ddc4f83b6057d8ae9d014d9",
            "3509facc5bcd473ab7e9392e19933bac",
            "4ce28cecb0894ad682af7736b03c662d",
            "fc255894791e4478bcd53ff93ab17848",
            "2b1643aaa3ce47d2ae4654f86f9e1269",
            "44adc452f84e4d269f79db168f2df364",
            "ccaede554a154ef59bef70a6ddee8d37",
            "487992485da749f2b96fa032b1fc1b69",
            "a9d4146039a1488aa66e206cca4f02db",
            "20dee970429443c998ea455a69241c93",
            "691324536f964a4fb08cac0308207447",
            "37d74d8d1ac74aed9232bd18da709c9e",
            "e985879804d04808aa3fcf9b58e5ba25",
            "5d785ac438a747c882c87e47c0d67674",
            "5f94b9c0bbfa414eacfed1ec17865ca0",
            "bd1460c1e0894be09822ec8f2c958c5e",
            "e07b85a75959435fb69834b6cf36760d",
            "26f726bce70a4819b57fc1964639b8a8",
            "0e36bfd01b614da9a625a42bf37534d3",
            "cbf7ff1e9f4942568af30ac18bf637a0",
            "646813f3d11946f288549e55494d5224",
            "98b143b4b0734ca58c0a0b64fea3cc41",
            "45874387086546d488bece69922ddb58",
            "93b8fc37c62a4ef28637f7b4ba22327b",
            "3300cd3c745349ea988064e2c6e36da4",
            "bf5c081477434f8abaf3828838342124",
            "db2e2b54916c49319d9d3f3f3b114ff4",
            "d5c0adc119d64bee815af25c32ceeac6",
            "501fa6f9ddae4d9a9fa045d879045c0f",
            "85066906be20401d8862c9285ab42a49",
            "1d40925603a3443e91851eefa24ab7c9",
            "571ce9e8ce474a2faaab291261d31fdd",
            "1424d1297c3345ae8b53eda1b9676c7b",
            "b82b9cbe51b4410db427edb02514bf4d",
            "580721bf610543f9ba765cedb83a8967",
            "be4638d5404248fdae05ee03dbd5d9a7",
            "99c1f189e7294a54a5c787b1b785a819",
            "07d3bf388d2a40b0a489d726c07c204a",
            "f4d7e654a5da4faa8389fca61dc1a3c1",
            "191eaf9233474683b4d5cf5a08245211",
            "54fe12b6eb32430ba35d34758ecd970a",
            "d3495aaae6f240a995b6f4e95d035b6d",
            "16c1273abe9743b683996ad2a843b63f",
            "e9797a80e350425486a198c07adb7ade",
            "12879a5e32e745bbaddea7ba06d57485",
            "d2817491c6c34e24b207542095389a43",
            "5b864f3a66c1429382d3602b263f8b5a"
          ]
        },
        "id": "m165B96bFoFZ",
        "outputId": "d6d6b96c-3c94-4928-fd45-9ea740198ea3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23ace39444cd4ac089e59eaeb0fc4c27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acec74060c824291a06a11509e6abc97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c943c09cc8a4362b79e84d93c851f2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb19300ff5944d3a957758c3f348316f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)figuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e6e7c706f904e34823c88781cb60631"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
            "- configuration_falcon.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.cf4b3c42ce2fdfe24f753f0f0d179202fea59c99.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)n/modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ed14ca5fea34c83a96b9c6f8264206b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n",
            "- modeling_falcon.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)model.bin.index.json:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11bd3678688b4890afa80a6510c27163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fadc02fbc66e468bbe7b7dea06e485ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc255894791e4478bcd53ff93ab17848"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f94b9c0bbfa414eacfed1ec17865ca0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf5c081477434f8abaf3828838342124"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99c1f189e7294a54a5c787b1b785a819"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "bz-BpcGoGlTu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline)\n",
        "\n",
        "model_name = \"intfloat/e5-large-v2\"\n",
        "hf = HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "a1259bfc65a64b4fb8d726169b739b35",
            "527f0d34c8e74603b3a69efd405af292",
            "95c3082409cc42a7a51f7ce790b5ae46",
            "0fa03dba5f254f8b837420a6cd7a14a3",
            "883d88e53daa4f5db28923f94f02268e",
            "590ab27369a64371a673102fd93120db",
            "4f29f549870648aa8154db612fe97122",
            "dc47d7990ae843538f4a22a596ff9092",
            "aca88ddf9e104605a598fc988f96b85c",
            "cc0ef2ea57e24fc6b0b76e316ed55bde",
            "cbaa37621d0a4056bd29f8bf55afe6f2",
            "07e9434469da46ed8179254a668ba79a",
            "480a6a8bad2b45c2945b6c618fb4bd68",
            "31035021910d4b32aaf2b7128d9e9f3b",
            "a8e87d9d5e1b483983827f5e73d6ab6c",
            "00e2b83588b443dd854ea1365e1e2a73",
            "8bf9a0275968415a8fda21b48ccb5250",
            "918f5349596847a4b85c2b0dcd4017fd",
            "3b48825cf8984cf0bba091d205f1f72a",
            "f82ae7bad9b94c7eb27a2e2313965fc3",
            "fc13c8ecad6b4116a07aca4aa37c8c1b",
            "5c9b229316974127afbfa5c50cab55db",
            "c1fb3b9e13ed4e7e980ddeffe4b87209",
            "9d99716aed714637a8db33ab1afd202f",
            "76c3e01cdd39486faabdacda2b03c6bd",
            "a06f2e83cdd642eca9d5460bee2b097f",
            "a6513e6f4c704a128c08a79313e26568",
            "b5997a160fdf41238c8fcfbb799b1985",
            "95a510f220b14dcd91c72c5c92198068",
            "cd7f9ca3561d49289595e41945a7faa9",
            "e5e8ae7c027b4b0ca5e98fa86b289bba",
            "408610b28e234521af133dca37313df3",
            "cb9c591f188b40dfb91715cf2dca743b",
            "880f85bde01d48a3929fd1a9967e3a03",
            "6c693aafb18a4e82871d2cf94fa686ac",
            "cb62b60823af4017ae2de0a61fe62e04",
            "620d531442f547a2ba3360e8dbacd794",
            "d72e6f9f4db747b2835b9fead52523a3",
            "f91bd6c7a1b546e28bc3f51e81f03916",
            "da6b0e1341564f83951369bcab38eb49",
            "2d2f8dc7374d42d19a100aec5cdcce31",
            "70851ba40b8541ca8ff69f2d4560718f",
            "2df27324712441619361da714a9cea3d",
            "0b68b2ea4ef747b0b1f04898c789d56f",
            "a8d9fc4664cc4bc188562937c55a60da",
            "53bd1a04dddf4a5da6917c031450215a",
            "0e18f9595710472c9d2263452269fbf4",
            "1d2c3d773efa4c07a27f32f5f5bf2b28",
            "035c895beb4f48f49299c49417c95fb0",
            "31409952cb7849ebb35b2e5742992438",
            "9381a9cd1bca429c80c9bc48eca03fa5",
            "b1634092f9754ec1abb7000a5cb53263",
            "9414e6bb012e44ee94324770c50ff68b",
            "04dd2f98d0a3472ea971e62d1cb96d3d",
            "fd119557a9174986adc42e1da01b7032",
            "22c8ebcf7fa0431eb1c07762b98253e7",
            "7ea4eb42310142118b183264ed8e73ec",
            "40f38da209964620984547ede0c50616",
            "8de671837da84f7ea567da989536f6ef",
            "e4f2379d693447a4895031d9bc8ba836",
            "3b39cf2c58b44afea3c8bcccc883a877",
            "fed46bf7458e47869e9bf78889ca3995",
            "8e7108c88ce94654b053ba0a7fbdb26d",
            "6ebacc14a32142ffb2e97829afb00aa5",
            "3b4f5a94308e4b36a1f89ec1b1491133",
            "c9ca07d13dc64939acf628c10ec5b36f",
            "8dad4d6f9ca949c3ac4e9cd685004ec4",
            "a25a6cb255ba402b85a6ace764097c3d",
            "d322aa7acd37467a8b1d879fc2860664",
            "15c67f4847f140a2ba1568f359ecdf3a",
            "7cc492aa0bb84b948587ecd57165680f",
            "53cb147ebf2e478aa5c697d53be7b060",
            "702293a2c1124e088ce651ab3025de7a",
            "290c10d8539146c8a75d53375f8d3fb9",
            "a5248551810a44849f58a28f9193853d",
            "29542653f80b4c189cfba8a8813d59d9",
            "e3633de97d6640bdb2c9f395dc76a42b",
            "fdb987db83e447bc837ea4ffc97501e7",
            "a78d6d03fca84da69375ec38eec4b06d",
            "a48352859bec4f40931c600dba67c8d1",
            "ee2983bdec244a7287cf943a81a28800",
            "e8209c72d5c14cfba99dda05ab14f455",
            "cae8dc96c6784c9399f4f0933e9d19c6",
            "0797bc9595934cfb96d8847d1c53dbdd",
            "9d8abc98d92b498690e03ebc7baa89eb",
            "f8f71802f93c41e9ab009bc86f304fc4",
            "211b0fb4b0eb469aa612097474969a3c",
            "32692561261444e5b42125c6594a60cf",
            "67e8675db11d4bc9b6313a247347daae",
            "31192faa4edc47c4a77eee26494aa85f",
            "d21410b42492449e83c4b20e03165182",
            "151259955c864aa3bd0ca8e4e43dffa5",
            "6dd5e0d586844c6ca9696b7952f88ec0",
            "2e3f95ab90884f73b9c50dc5d93f795a",
            "fedec7f59dba4ff791297a26edaa14d5",
            "15c40154be7b4d20b447be1828cf3bbd",
            "52375e45e63d486e953265811c9e1683",
            "5cdcb791e0884aab88c32b2b5891dd22",
            "a61fccad36324956b5c45a4e31962c62",
            "bb54dca511454f73ad28208054cae2b9",
            "04e9c7ee6b2c4188b35107e4c6dc9050",
            "d11802d7a62c4540b5e6fbc85f94c517",
            "e37d4ba17a6d41ffb58a94a1b6f89c49",
            "caa9010dd37c439e9f4d5beab0d55ac9",
            "545b279546eb42008e0aea4069c1a8b5",
            "c5fdc5a027b748498437a08291ba6fab",
            "924c02e6fdf5421a82330f8f07d35a18",
            "5eab3db94f2b4e1eba0a5024af758bf9",
            "3c6a5f1360724d73911fc26c35b90185",
            "30ad1c581a944f159ab4d3a5693d2443",
            "6b4a1d24dfe54d9491726fbacfe4ea26",
            "bfd5fda0dfe04a4b9f3d1d954dc91bdb",
            "ea5529e42e774cc392c0a06e2a06afa4",
            "a24b13dbb59740b2ba2adfbf5d872a70",
            "d87832d01fe64645b2cf0d8d2a4d53fd",
            "83ec0499e7e9458686194fe766d4b250",
            "2df314148ee7431a812471d6a91c6ae1",
            "fc9e315188354c4ea4810e4dfebc85fc",
            "6e41c905ba37403684c362c45369b487",
            "0a8939e2c2454886a38d3b4396e54f65",
            "ca641aee076246799faaac88ab3d8998",
            "6a3a10e0796f4f2ebf1da002cbf6c82d",
            "d442db11a67a47afa997aa9bc5ea66d7",
            "de9c2e64dcf24b2ab465ed2f5e87e3cd",
            "bc92e4428bb247dbb7670d9bdf366a5b",
            "4deef9b4e72b49f29aa0cfdd0ebfe93b",
            "b468399b770b43008c3d66f3159f192d",
            "d069eb1054c24b808d595f0c6aeade2c",
            "ca8d274983e443caa2035c2efd76d942",
            "89f3e40638bb4232ae8b3c44e5cbeb80",
            "ac8cda8dab944a4fb90ebfa0fbee2ff3",
            "e0ab47b151f54ebc903e67d87118aaf2",
            "e592393eb93740cf8497825af5bb6929",
            "0bba509c96cc4b2bb914751bb48ab000",
            "8eef688849b84f05aff7e30f593bf1ca",
            "64544d497df04a1c8ea0a6d4bededc7b",
            "081f1ecc12e14d16bae8c38e6a3d7560",
            "3899660c05ee4534a56b41f492210abd",
            "302d82378b934846b44bb35e58068d5c",
            "26b6551829184e5d9e65d68c29d5ce51",
            "6251b8ae5081486c93550b7379dbbe57",
            "05f583ce3b514e0bba48e04038dfeb7a",
            "9be18d2416d846c396c78a7c7b67aab2"
          ]
        },
        "id": "Bja5zEuwK6IG",
        "outputId": "1b1961ff-370e-446c-9237-228a903058b9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)1d311/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1259bfc65a64b4fb8d726169b739b35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07e9434469da46ed8179254a668ba79a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)b4e101d311/README.md:   0%|          | 0.00/67.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1fb3b9e13ed4e7e980ddeffe4b87209"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e101d311/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "880f85bde01d48a3929fd1a9967e3a03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)4e101d311/handler.py:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8d9fc4664cc4bc188562937c55a60da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22c8ebcf7fa0431eb1c07762b98253e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dad4d6f9ca949c3ac4e9cd685004ec4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdb987db83e447bc837ea4ffc97501e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67e8675db11d4bc9b6313a247347daae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)1d311/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb54dca511454f73ad28208054cae2b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b4a1d24dfe54d9491726fbacfe4ea26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)b4e101d311/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a3a10e0796f4f2ebf1da002cbf6c82d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)101d311/modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e592393eb93740cf8497825af5bb6929"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the DB"
      ],
      "metadata": {
        "id": "qxHT0nyIHdNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets the directory where the embeddings will be stored.\n",
        "persist_directory = 'db'\n",
        "\n",
        "# Sets the HuggingFaceEmbeddings object as the embedding to use.\n",
        "embedding = hf\n",
        "\n",
        "# Uses the Chroma module to convert the texts into embeddings using the specified HuggingFace embeddings.\n",
        "# The resulting embeddings are stored in the persist_directory.\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=hf,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "UK8luCsJHdyo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persists the generated embeddings database to disk.\n",
        "vectordb.persist()\n",
        "\n",
        "# Releases the memory held by the vectordb object by setting it to None.\n",
        "vectordb = None\n",
        "\n",
        " #Re-initializes the Chroma object from the persisted directory with the specified HuggingFace embeddings.\n",
        "vectordb = Chroma(persist_directory=persist_directory,\n",
        "                  embedding_function=hf)\n"
      ],
      "metadata": {
        "id": "PaqNrLk3cqLD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initializes a retriever object from the vectordb with a specified number of search results (k=3).\n",
        "# The vectordb.as_retriever() function is likely converting the Chroma object, which contains vectorized representations of text, into a retriever object.\n",
        "# The retriever can be used to find the most similar vectors in the database given a query vector.\n",
        "# The search_kwargs={\"k\": 3} argument suggests that the retriever will return the top 3 most similar vectors for each query.\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# create the chain to answer questions\n",
        "# Initializes a RetrievalQA object with the specified HuggingFacePipeline (llm), retriever, and chain type.\n",
        "# The return_source_documents parameter set to True means the original source documents will be included in the returned results.\n",
        "qa_chain = RetrievalQA.from_chain_type(llm= llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)\n",
        "\n",
        "\n",
        " # This function processes the response from a Language Model (llm) and prints the result and sources.\n",
        "def process_llm_response(llm_response):\n",
        "    # Prints the 'result' field from the response, which likely contains the answer from the language model.\n",
        "    print(llm_response['result'])\n",
        "\n",
        "    print('\\n\\nSources:')\n",
        "    # Iterates over the 'source_documents' field in the response, which contains the documents where the answer was found.\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        # Prints the 'source' metadata from each document.\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "4OsDdWblHvrF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Could you please enumerate the companies that have been highlighted for their potential stock growth\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgi-flz_Ira-",
        "outputId": "d8a3d3c1-9b3e-4239-91ee-cdb1fd4e9b87"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 300, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/stock_market.txt\n",
            "stock_market_june_2023/Microsoft Corporation.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much has Microsoft invested in OpenAI?\"\n",
        "llm_response = qa_chain(query)\n",
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RifX2tVjI01W",
        "outputId": "9ce58f19-9893-497d-91ea-420f7e9ff209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 280, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How much has Microsoft invested in OpenAI?',\n",
              " 'result': ' Microsoft',\n",
              " 'source_documents': [Document(page_content='Let’s focus on Microsoft’s artificial intelligence (AI) prospects. As AI propels itself into the mainstream, it’s not surprising to see investors eager to fortify their portfolios with AI stocks. Microsoft’s recent $1 billion investment in OpenAI – the creator of ChatGPT and the AI image generator Dall-E- positions the stock as a prime candidate for investment.', metadata={'source': 'stock_market_june_2023/Microsoft Corporation.txt'}),\n",
              "  Document(page_content='Microsoft’s strategic move to integrate OpenAI’s products within its platform positions the company as a preferred platform for organizations looking to develop AI models or incorporate them into their business operations. Microsoft’s focus on building AI tools as platforms is a savvy strategic decision that will likely broaden its already considerable enterprise customer base and service suite.', metadata={'source': 'stock_market_june_2023/Microsoft Corporation.txt'}),\n",
              "  Document(page_content='This Microsoft-OpenAI partnership clearly conveys Microsoft’s intent and efforts to incorporate AI capabilities into its services. Starting with its cloud service, Azure – second only to Amazon Web Services (AWS) in global cloud market share and a key component of Microsoft’s business – Microsoft is showcasing its commitment to AI.', metadata={'source': 'stock_market_june_2023/Microsoft Corporation.txt'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What were the reasons behind Shopify's decision to lay off a portion of its workforce\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ym4waxoJG6u",
        "outputId": "91e8029e-65aa-46f6-c459-d69a0186ade1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 240, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Sources:\n",
            "stock_market_june_2023/Shopify.txt\n",
            "stock_market_june_2023/Shopify.txt\n",
            "stock_market_june_2023/Shopify.txt\n"
          ]
        }
      ]
    }
  ]
}